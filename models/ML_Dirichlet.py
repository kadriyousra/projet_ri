import math
import os
import sys
from collections import defaultdict
from typing import List, Dict, Tuple


class LanguageModelDirichlet:
    """Language Model avec Dirichlet Smoothing (Bayesian Smoothing)"""
    
    def __init__(self, inverted_index_path, doc_term_matrix_path, mu_param=None):
        """
        Args:
            inverted_index_path: Chemin vers l'inverted index
            doc_term_matrix_path: Chemin vers la matrice document-terme
            mu_param: ParamÃ¨tre Î¼ pour le lissage Dirichlet
                     Si None, calculÃ© automatiquement comme: |C| / N
                     (taille collection / nombre documents)
        """
        # Charger l'index inversÃ© (frÃ©quences des termes)
        self.inverted_index = self._load_inverted_index(inverted_index_path)
        
        # Charger les longueurs des documents
        self.doc_lengths = self._load_doc_lengths(doc_term_matrix_path)
        
        # Nombre de documents
        self.N = len(self.doc_lengths)
        
        # Liste des doc_ids
        self.doc_ids = sorted(list(self.doc_lengths.keys()))
        
        # Calculer les statistiques de la COLLECTION (corpus)
        self._compute_collection_statistics()
        
        # ParamÃ¨tre Î¼ pour Dirichlet
        if mu_param is None:
            # Calcul automatique: Î¼ = |C| / N
            self.mu_param = self.collection_size / self.N if self.N > 0 else 1000
            print(f"   Î¼ calculÃ© automatiquement: {self.mu_param:.2f}")
        else:
            self.mu_param = mu_param
            print(f"   Î¼ fourni: {self.mu_param}")
    
    def _load_inverted_index(self, filepath):
        """Charge l'inverted index depuis le fichier"""
        inverted_index = defaultdict(dict)
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 3:
                    term = parts[0]
                    doc_id = int(parts[1])
                    freq = int(parts[2])
                    inverted_index[term][doc_id] = freq
        return inverted_index
    
    def _load_doc_lengths(self, filepath):
        """Charge les longueurs des documents (|d| = somme des frÃ©quences)"""
        doc_lengths = defaultdict(int)
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 3:
                    doc_id = int(parts[0])
                    freq = int(parts[2])
                    doc_lengths[doc_id] += freq
        return doc_lengths
    
    def _compute_collection_statistics(self):
        """
        Calcule les statistiques de la COLLECTION (corpus entier)
        
        Pour chaque terme:
        - collection_freq[terme] = somme des frÃ©quences dans TOUS les documents
        
        Taille de la collection:
        - collection_size = somme de toutes les frÃ©quences de tous les termes
        """
        self.collection_freq = defaultdict(int)
        
        # Pour chaque terme, sommer ses frÃ©quences dans tous les documents
        for term, doc_freqs in self.inverted_index.items():
            for doc_id, freq in doc_freqs.items():
                self.collection_freq[term] += freq
        
        # Taille totale de la collection = somme de toutes les frÃ©quences
        self.collection_size = sum(self.collection_freq.values())
    
    def process_query(self, query_text):
        """PrÃ©traite une requÃªte (simple split en minuscules)"""
        return query_text.lower().split()
    
    def get_term_freq(self, term, doc_id):
        """Obtient la frÃ©quence d'un terme dans un document"""
        return self.inverted_index.get(term, {}).get(doc_id, 0)
    
    def calculate_p_mle_doc(self, term: str, doc_id: int) -> float:
        """
        Calcule P_MLE(w|d) = freq(w,d) / |d|
        
        ProbabilitÃ© du terme dans le DOCUMENT
        """
        freq_w_d = self.get_term_freq(term, doc_id)
        doc_length = self.doc_lengths.get(doc_id, 0)
        
        if doc_length == 0:
            return 0.0
        
        return freq_w_d / doc_length
    
    def calculate_p_mle_collection(self, term: str) -> float:
        """
        Calcule P_MLE(w|C) = freq(w,C) / |C|
        
        oÃ¹:
        - freq(w,C) = frÃ©quence du terme dans la COLLECTION (somme sur tous les docs)
        - |C| = taille de la collection (somme de toutes les frÃ©quences)
        
        ProbabilitÃ© du terme dans la COLLECTION (corpus entier)
        """
        freq_w_c = self.collection_freq.get(term, 0)
        
        if self.collection_size == 0:
            return 0.0
        
        return freq_w_c / self.collection_size
    
    def calculate_p_dir(self, term: str, doc_id: int) -> float:
        """
        Calcule P_Dir(w|d) avec lissage Dirichlet
        
        Formule: P_Dir(w|d) = [N / (N + Î¼)] * P_MLE(w|d) + [Î¼ / (N + Î¼)] * P_MLE(w|C)
        
        oÃ¹:
        - N = |d| = longueur du document (nombre de mots dans le document)
        - Î¼ = paramÃ¨tre de lissage Dirichlet
        - P_MLE(w|d) = tf(w,d) / |d|
        - P_MLE(w|C) = freq(w,C) / |C|
        
        Cette formule peut aussi s'Ã©crire:
        P_Dir(w|d) = [tf(w,d) + Î¼ * P_MLE(w|C)] / (|d| + Î¼)
        
        Args:
            term: Le mot
            doc_id: ID du document
        
        Returns:
            ProbabilitÃ© avec lissage Dirichlet (toujours > 0 si le terme existe dans la collection)
        """
        # Longueur du document
        doc_length = self.doc_lengths.get(doc_id, 0)
        
        if doc_length == 0:
            return 0.0
        
        # FrÃ©quence du terme dans le document
        tf_w_d = self.get_term_freq(term, doc_id)
        
        # ProbabilitÃ© du terme dans la collection
        p_mle_collection = self.calculate_p_mle_collection(term)
        
        # Formule Dirichlet: [tf(w,d) + Î¼ * P_MLE(w|C)] / (|d| + Î¼)
        numerator = tf_w_d + self.mu_param * p_mle_collection
        denominator = doc_length + self.mu_param
        
        p_dir = numerator / denominator
        
        return p_dir
    
    def calculate_rsv(self, query_terms: List[str], doc_id: int) -> float:
        """
        Calcule le RSV (Retrieval Status Value) avec Dirichlet Smoothing
        
        RSV(Q, d) = âˆ P_Dir(w|d) pour w âˆˆ Q
        
        oÃ¹ P_Dir(w|d) = [tf(w,d) + Î¼Â·P_MLE(w|C)] / (|d| + Î¼)
        
        Args:
            query_terms: Liste des termes de la requÃªte
            doc_id: ID du document
        
        Returns:
            RSV score (produit des probabilitÃ©s avec lissage Dirichlet)
        """
        rsv = 1.0
        
        for term in query_terms:
            p_dir = self.calculate_p_dir(term, doc_id)
            
            # MÃªme si p_dir est trÃ¨s petit, on ne met pas 0
            # (sauf si le terme n'existe nulle part dans la collection)
            if p_dir == 0:
                return 0.0
            
            rsv *= p_dir
        
        return rsv
    
    def rank_documents(self, query_terms: List[str], top_k: int = None) -> List[Tuple[int, float]]:
        """
        Classe tous les documents pour une requÃªte
        
        Args:
            query_terms: Liste des termes de la requÃªte
            top_k: Si spÃ©cifiÃ©, limite le nombre de rÃ©sultats (pour affichage)
                   Si None, retourne TOUS les documents (requis pour Ã©valuation)
        
        Returns:
            Liste de tuples (doc_id, rsv_score) triÃ©e par score dÃ©croissant
        """
        # Calculer RSV pour tous les documents
        doc_scores = []
        
        for doc_id in self.doc_ids:
            rsv = self.calculate_rsv(query_terms, doc_id)
            doc_scores.append((doc_id, rsv))
        
        # Trier par score dÃ©croissant
        doc_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Retourner top_k si spÃ©cifiÃ© (pour affichage uniquement)
        if top_k is not None:
            doc_scores = doc_scores[:top_k]
        
        return doc_scores
    
    def search(self, query_terms: List[str], top_k: int = 10, 
              verbose: bool = False, return_all: bool = False) -> List[int]:
        """
        Recherche les documents pertinents pour une requÃªte
        
        Args:
            query_terms: Liste des termes de la requÃªte
            top_k: Nombre de documents Ã  retourner (ignorÃ© si return_all=True)
            verbose: Afficher les rÃ©sultats
            return_all: Si True, retourne TOUS les documents (pour Ã©valuation)
        
        Returns:
            Liste des doc_ids classÃ©s par pertinence
        """
        # Obtenir tous les documents classÃ©s
        doc_scores = self.rank_documents(query_terms, top_k=None)
        
        if verbose and doc_scores:
            display_k = min(top_k, len(doc_scores))
            print(f"\nğŸ” Top {display_k} documents:")
            print(f"{'Rang':<6} {'Doc ID':<10} {'RSV Score':<15}")
            print("-" * 35)
            for rank, (doc_id, score) in enumerate(doc_scores[:display_k], 1):
                print(f"{rank:<6} {doc_id:<10} {score:.10f}")
        
        # Extraire les doc_ids
        ranked_list = [doc_id for doc_id, score in doc_scores]
        
        # Limiter seulement si demandÃ© ET pas return_all
        if top_k and not return_all:
            ranked_list = ranked_list[:top_k]
        
        return ranked_list


# ============================================================================
# Ã‰VALUATION COMPLÃˆTE AVEC METRICS.PY
# ============================================================================

if __name__ == "__main__":
    
    # Ajouter le dossier src et evaluation au path
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(current_dir)
    src_dir = os.path.join(project_dir, 'src')
    eval_dir = os.path.join(project_dir, 'evaluation')
    sys.path.insert(0, src_dir)
    sys.path.insert(0, eval_dir)
    
    from medline_parser import parse_med_qry, parse_med_rel
    from preprocessing import MEDLINEPreprocessor
    from metrics import IRMetrics
    
    # Chemins
    INVERTED_INDEX_PATH = os.path.join(project_dir, "data", "ouput", "inverted_index.txt")
    DOC_TERM_MATRIX_PATH = os.path.join(project_dir, "data", "ouput", "document_term_matrix.txt")
    MED_QRY_PATH = os.path.join(project_dir, "data", "MED.QRY")
    MED_REL_PATH = os.path.join(project_dir, "data", "MED.REL")
    
    # VÃ©rifier les fichiers
    for path, name in [(INVERTED_INDEX_PATH, "Inverted Index"),
                       (DOC_TERM_MATRIX_PATH, "Document-Term Matrix"),
                       (MED_QRY_PATH, "MED.QRY"),
                       (MED_REL_PATH, "MED.REL")]:
        if not os.path.exists(path):
            print(f"âŒ ERREUR: Fichier non trouvÃ©: {path}")
            exit(1)
    
    print("="*80)
    print("Ã‰VALUATION COMPLÃˆTE - LANGUAGE MODEL DIRICHLET SMOOTHING")
    print("="*80)
    
    # 1. CrÃ©er le modÃ¨le (Î¼ calculÃ© automatiquement)
    print("\nğŸ“š Ã‰tape 1: Initialisation du modÃ¨le Language Model Dirichlet")
    print("   Technique: Bayesian Smoothing (Dirichlet Prior)")
    print("   Formule: P_Dir(w|d) = [tf(w,d) + Î¼Â·P_MLE(w|C)] / (|d| + Î¼)")
    print("   Calcul de Î¼: |C| / N (taille collection / nombre documents)")
    lm_dir = LanguageModelDirichlet(
        inverted_index_path=INVERTED_INDEX_PATH,
        doc_term_matrix_path=DOC_TERM_MATRIX_PATH,
        mu_param=None  # CalculÃ© automatiquement
    )
    print(f"âœ… ModÃ¨le initialisÃ©")
    print(f"   - Documents: {lm_dir.N}")
    print(f"   - Vocabulaire: {len(lm_dir.inverted_index)} termes")
    print(f"   - Taille de la collection |C|: {lm_dir.collection_size} mots")
    print(f"   - ParamÃ¨tre Î¼: {lm_dir.mu_param:.2f}")
    
    # 2. Charger les donnÃ©es
    print("\nğŸ“„ Ã‰tape 2: Chargement des donnÃ©es")
    queries = parse_med_qry(MED_QRY_PATH)
    relevance_judgments = parse_med_rel(MED_REL_PATH)
    print(f"âœ… {len(queries)} requÃªtes chargÃ©es")
    print(f"âœ… {len(relevance_judgments)} jugements de pertinence chargÃ©s")
    
    # 3. CrÃ©er le preprocessor
    preprocessor = MEDLINEPreprocessor()
    
    # 4. Initialiser le systÃ¨me de mÃ©triques
    print("\nğŸ“Š Ã‰tape 3: Initialisation du systÃ¨me d'Ã©valuation")
    metrics = IRMetrics(relevance_judgments, model_name="LM_Dirichlet_Auto")
    
    # 5. Collecter tous les rÃ©sultats
    print("\nğŸ” Ã‰tape 4: Traitement de toutes les requÃªtes")
    results_per_query = {}
    relevance_scores_per_query = {}
    
    for query in queries:
        query_id = query.query_id
        query_text = query.text
        
        # Preprocesser la requÃªte
        query_terms = preprocessor.preprocess_text(query_text)
        
        # Obtenir TOUS les documents classÃ©s
        doc_scores = lm_dir.rank_documents(query_terms, top_k=None)
        
        # Extraire les doc_ids et les scores
        ranked_list = [doc_id for doc_id, score in doc_scores]
        scores_dict = {doc_id: score for doc_id, score in doc_scores}
        
        results_per_query[query_id] = ranked_list
        relevance_scores_per_query[query_id] = scores_dict
        
        print(f"   RequÃªte {query_id}: {len(ranked_list)} documents classÃ©s")
    
    # 6. Ã‰valuer le systÃ¨me complet
    print("\nğŸ“ˆ Ã‰tape 5: Ã‰valuation complÃ¨te du systÃ¨me")
    all_results = metrics.evaluate_all_queries(
        results_per_query=results_per_query,
        relevance_scores_per_query=relevance_scores_per_query,
        plot_curves=True,
        save_results=True,
        verbose=True  # âœ… CHANGEMENT: verbose=True pour sauvegarder les mÃ©triques globales
    )
    
    print("\n" + "="*80)
    print("âœ… Ã‰VALUATION TERMINÃ‰E")
    print("="*80)
    print(f"ğŸ“ RÃ©sultats sauvegardÃ©s:")
    print(f"   - results/LM_Dirichlet_Auto_results.txt")
    print(f"   - results/figures/LM_Dirichlet_Auto/")
    print("="*80)